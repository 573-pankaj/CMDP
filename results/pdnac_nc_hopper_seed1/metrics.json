{
  "training": {
    "iteration": [
      0,
      10,
      20,
      30,
      40,
      50,
      60,
      70,
      80,
      90
    ],
    "episode_reward": [
      -126.40280797923273,
      -127.46510125788328,
      -124.95719609142085,
      -130.03285237385813,
      -131.23540346394628,
      -120.98244924241403,
      -131.32376923959657,
      -127.25981684331732,
      -131.9063728420855,
      -129.47358257103593
    ],
    "reward_std": [
      4.456759529583908,
      10.205773437480042,
      5.7575802885869924,
      6.464532620870625,
      14.362369191408487,
      12.348716863592623,
      11.864962357520035,
      10.46867044117754,
      9.691690880749107,
      10.890508060778076
    ],
    "cost_estimate": [
      -166.98468200964223,
      -167.7038288151754,
      -165.81236510422792,
      -168.06641233465922,
      -171.26785012208802,
      -166.24427224110292,
      -172.69304140727837,
      -166.4981608417076,
      -173.46215977685642,
      -168.06128755758868
    ],
    "cost_std": [
      4.696410335037242,
      7.351856929203398,
      9.71663692191765,
      6.615337360117268,
      10.056429907989498,
      8.809586222883995,
      5.451001500725229,
      6.832616133386678,
      4.247682723804526,
      8.158932742349913
    ],
    "lambda": [
      4.8590123924441286e-08,
      6.253612082218751e-05,
      8.999866986414418e-05,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      3.589705374906771e-05,
      0.0
    ],
    "policy_grad_norm": [
      0.005951034836471081,
      0.0017224818002432585,
      0.011458833701908588,
      0.0016391457756981254,
      0.01605217717587948,
      0.030753275379538536,
      0.002984786406159401,
      0.002322125481441617,
      0.03480130806565285,
      0.006863994523882866
    ],
    "constraint_violation": [
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0
    ]
  },
  "evaluation": {}
}