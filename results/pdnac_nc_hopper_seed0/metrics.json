{
  "training": {
    "iteration": [
      0,
      10,
      20,
      30,
      40,
      50,
      60,
      70,
      80,
      90
    ],
    "episode_reward": [
      -137.72068009081016,
      -141.63930674531858,
      -145.2863998001939,
      -151.8425893437372,
      -140.4877965451387,
      -145.08201730390246,
      -137.8761343724943,
      -152.4934657597856,
      -147.7338853124206,
      -143.75683548112582
    ],
    "reward_std": [
      7.743433606803852,
      9.749029566881214,
      9.188728999284514,
      11.03538332472831,
      12.23878870069402,
      11.407101466590825,
      9.231170312423215,
      9.230748506297942,
      4.203653502861729,
      8.201369488030547
    ],
    "cost_estimate": [
      -186.5483658517744,
      -183.5372875818908,
      -186.7143986449054,
      -181.88381196747136,
      -184.20489794769512,
      -182.30621986536568,
      -186.872378936151,
      -181.6966628958565,
      -185.2244672146362,
      -183.96117694270674
    ],
    "cost_std": [
      4.125049781815967,
      4.535367588028033,
      3.0260507113371258,
      7.047004213501722,
      3.0933247060515443,
      6.800403990188955,
      4.590744992889048,
      8.278604648588622,
      4.106557542203304,
      3.4500359514850047
    ],
    "lambda": [
      0.0,
      0.0,
      9.798487008083612e-05,
      0.0,
      0.0,
      0.0,
      1.2394884834066033e-06,
      9.791552656679414e-06,
      0.00013999092334415764,
      0.0
    ],
    "policy_grad_norm": [
      0.012387682683765888,
      0.012488886713981628,
      0.011825903318822384,
      0.008645103313028812,
      0.009110010229051113,
      0.010151666589081287,
      0.011887880973517895,
      0.016563385725021362,
      0.003749314695596695,
      0.004342366009950638
    ],
    "constraint_violation": [
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0
    ]
  },
  "evaluation": {}
}