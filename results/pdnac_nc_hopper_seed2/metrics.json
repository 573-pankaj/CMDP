{
  "training": {
    "iteration": [
      0,
      10,
      20,
      30,
      40,
      50,
      60,
      70,
      80,
      90
    ],
    "episode_reward": [
      -139.32758150230592,
      -140.44741834005066,
      -137.77274063658848,
      -135.19724566059654,
      -141.68614581290132,
      -140.67584017412287,
      -136.15222642675354,
      -139.31537835145005,
      -144.1738735196072,
      -134.91024189549742
    ],
    "reward_std": [
      6.179366516524318,
      4.991595372317837,
      2.261681421689401,
      7.314513154205704,
      5.907481927457245,
      2.710126231139038,
      6.7853389153319466,
      13.080643103223805,
      4.220646201419278,
      9.312547377283606
    ],
    "cost_estimate": [
      -184.40911676573617,
      -190.01103067109088,
      -188.6317107104281,
      -185.02496731810643,
      -189.30788920145199,
      -192.68901661879843,
      -187.33730832719556,
      -182.5356163934638,
      -190.45829320876285,
      -186.08321500325405
    ],
    "cost_std": [
      6.28937189090516,
      5.526394611970723,
      8.453059413251903,
      5.996407485365886,
      3.9034776316550546,
      2.2091040712029653,
      2.142380479332304,
      3.5798135028802434,
      3.9410335223852395,
      8.529880424987276
    ],
    "lambda": [
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "policy_grad_norm": [
      0.013979623094201088,
      0.006292854435741901,
      0.0044479975476861,
      0.013322168029844761,
      0.03690849617123604,
      0.010829916223883629,
      0.011691565625369549,
      0.0006628688424825668,
      0.0023160947021096945,
      0.01839231699705124
    ],
    "constraint_violation": [
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0
    ]
  },
  "evaluation": {}
}